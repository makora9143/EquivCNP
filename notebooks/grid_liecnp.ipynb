{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from lienp.liegroups import *\n",
    "from lienp.modules import *\n",
    "from lienp.modules.lieconv import SeparableLieConv\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class GridLieCNP(nn.Module):\n",
    "    \"\"\"Grid LieGroup Convolutional Conditional Neural Process\n",
    "    \"\"\"\n",
    "    def __init__(self, channel=1, group=T(2)):\n",
    "        super().__init__()\n",
    "        self.channel = channel\n",
    "        self.group = group\n",
    "\n",
    "        self.conv_theta = LieConv(channel, 128, group=group,\n",
    "                                  num_nbhd=81, sampling_fraction=1., fill=1 / 10,\n",
    "                                  use_bn=True, mean=True, cache=True)\n",
    "\n",
    "        self.cnn = nn.Sequential(\n",
    "            Apply(nn.Linear(128 * 2, 128), dim=1),\n",
    "            ResBlock(128, 128, mean=True, group=group),\n",
    "            ResBlock(128, 128, mean=True, group=group),\n",
    "            ResBlock(128, 128, mean=True, group=group),\n",
    "            ResBlock(128, 128, mean=True, group=group),\n",
    "            Apply(nn.Linear(128, 2 * channel))\n",
    "        )\n",
    "        self.pos = nn.Softplus()\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, C, W, H = x.shape\n",
    "        ctx_coords, ctx_density, ctx_signal, ctx_mask = self.get_masked_image(x)\n",
    "        lifted_ctx_coords, lifted_ctx_density, lifted_ctx_mask = self.group.lift((ctx_coords, ctx_density, ctx_mask), 1)\n",
    "        lifted_ctx_signal, _ = self.group.expand_like(ctx_signal, ctx_mask, lifted_ctx_coords)\n",
    "\n",
    "        lifted_ctx_coords, density_prime, lifted_ctx_mask = self.conv_theta((lifted_ctx_coords, lifted_ctx_density, lifted_ctx_mask))\n",
    "        _, signal_prime, _ = self.conv_theta((lifted_ctx_coords, lifted_ctx_signal, lifted_ctx_mask))\n",
    "\n",
    "        ctx_h = torch.cat([density_prime, signal_prime], -1)\n",
    "        _, f, _ = self.cnn((lifted_ctx_coords, ctx_h, lifted_ctx_mask))\n",
    "        mean, std = f.split(self.channel, -1)\n",
    "\n",
    "        mean = mean.squeeze(-1)\n",
    "        std = self.pos(std).squeeze(-1)\n",
    "        return mean, std.diag_embed(), ctx_density.reshape(B, H, W, C).permute(0, 3, 1, 2)\n",
    "\n",
    "    def predict(self, x, ctx_coords, ctx_density, ctx_signal, ctx_mask):\n",
    "        B, C, W, H = x.shape\n",
    "        lifted_ctx_coords, lifted_ctx_density, lifted_ctx_mask = self.group.lift((ctx_coords, ctx_density, ctx_mask), 1)\n",
    "        lifted_ctx_signal, _ = self.group.expand_like(ctx_signal, ctx_mask, lifted_ctx_coords)\n",
    "\n",
    "        lifted_ctx_coords, density_prime, lifted_ctx_mask = self.conv_theta((lifted_ctx_coords, lifted_ctx_density, lifted_ctx_mask))\n",
    "        _, signal_prime, _ = self.conv_theta((lifted_ctx_coords, lifted_ctx_signal, lifted_ctx_mask))\n",
    "\n",
    "        ctx_h = torch.cat([density_prime, signal_prime], -1)\n",
    "        _, f, _ = self.cnn((lifted_ctx_coords, ctx_h, lifted_ctx_mask))\n",
    "        mean, std = f.split(self.channel, -1)\n",
    "\n",
    "        mean = mean.squeeze(-1)\n",
    "        std = self.pos(std).squeeze(-1)\n",
    "        return mean, std.diag_embed(), ctx_density.reshape(B, H, W, C).permute(0, 3, 1, 2)\n",
    "\n",
    "    def get_masked_image(self, img):\n",
    "        \"\"\"Get Context image and Target image\n",
    "\n",
    "        Args:\n",
    "            img (FloatTensor): image tensor (B, C, W, H)\n",
    "\n",
    "        Returns:\n",
    "            ctx_coords (FloatTensor): [B, W*H, 2]\n",
    "            ctx_density (FloatTensor): [B, W*H, C]\n",
    "            ctx_signal (FloatTensor): [B, W*H, C]\n",
    "\n",
    "        \"\"\"\n",
    "        B, C, H, W = img.shape\n",
    "        total_size = W * H\n",
    "\n",
    "        if self.training:\n",
    "            # uniform mask #FIXME\n",
    "            ctx_size = torch.empty(B, 1, 1, 1).uniform_(total_size / 100, total_size / 2)\n",
    "            # Broadcast to channel-axis [B, 1, W, H] -> [B，C, W, H]\n",
    "            ctx_mask = img.new_empty(B, 1, W, H).bernoulli_(p=ctx_size / total_size).repeat(1, C, 1, 1)\n",
    "        else:\n",
    "            # box mask\n",
    "            ctx_size = torch.empty(B, 1, 1, 1).uniform_(total_size / 100, total_size / 2)\n",
    "            # Broadcast to channel-axis [B, 1, W, H] -> [B，C, W, H]\n",
    "            ctx_mask = img.new_empty(B, 1, W, H).bernoulli_(p=ctx_size / total_size).repeat(1, C, 1, 1)\n",
    "\n",
    "        #  [B, C, W, H] -> [B, W, H, C] -> [B, W*H, C]\n",
    "        ctx_signal = (ctx_mask * img).permute(0, 2, 3, 1).reshape(B, -1, C)\n",
    "\n",
    "        ctx_coords = torch.linspace(-W / 2., W / 2., W, device=img.device)\n",
    "        # [B, W*H, 2]\n",
    "        ctx_coords = torch.stack(torch.meshgrid([ctx_coords, ctx_coords]), -1).reshape(1, -1, 2).repeat(B, 1, 1)\n",
    "        ctx_density = ctx_mask.reshape(B, -1, C)\n",
    "        # ctx_mask = torch.ones(*ctx_signal.shape[:2], device=img.device).bool()\n",
    "        ctx_mask = img.new_ones(B, W * H, dtype=torch.bool)\n",
    "        return ctx_coords, ctx_density, ctx_signal, ctx_mask\n",
    "\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, group=T(2), mean=False, r=2.):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.group = group\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            SeparableLieConv(in_channels, out_channels, num_nbhd=81, fill=1 / 15, sample=1., group=group, r=r, use_bn=False, mean=True),\n",
    "            Apply(nn.ReLU(inplace=True), dim=1),\n",
    "            SeparableLieConv(out_channels, out_channels, num_nbhd=81, fill=1 / 15, sample=1., group=group, r=r, use_bn=False, mean=True)\n",
    "        )\n",
    "        self.final_relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        shortcut = x\n",
    "        coords, values, mask = self.conv(x)\n",
    "        values = self.final_relu(values + shortcut[1])\n",
    "        return coords, values, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.utils import make_grid, save_image\n",
    "import torch\n",
    "from torchvision.transforms import functional as F\n",
    "from torchvision import transforms as tf\n",
    "from lienp.datasets.clockdigit import ClockDigit\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "def show(img):\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1,2,0)), interpolation='nearest')\n",
    "    \n",
    "    \n",
    "test_tf = tf.Compose([\n",
    "    tf.Pad(16),\n",
    "    tf.Lambda(lambda x: tf.functional.affine(x, 5, (0, 0), 2.0, 0)),\n",
    "    tf.ToTensor()\n",
    "])\n",
    "\n",
    "transforms = tf.Compose([\n",
    "            tf.Pad(16),\n",
    "            tf.RandomAffine(degrees=90, scale=(0.6, 0.9)),\n",
    "            tf.ToTensor()\n",
    "        ])\n",
    "batch_size = 1\n",
    "testset = ClockDigit(\"~/data/clockdigits\", download=True, transform=transforms)\n",
    "dl = DataLoader(testset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "rxso2 = GridLieCNP(channel=1, group=RxSO2())\n",
    "rxso2.load_state_dict(torch.load(\"weights/2dreg/RxSO2.pth\"))\n",
    "so2 = GridLieCNP(channel=1, group=SO2())\n",
    "so2.load_state_dict(torch.load(\"weights/2dreg/SO2.pth\"))\n",
    "se2 = GridLieCNP(channel=1, group=SE2())\n",
    "se2.load_state_dict(torch.load(\"weights/2dreg/SE2.pth\"))\n",
    "t2 = GridLieCNP(channel=1, group=T(2))\n",
    "t2.load_state_dict(torch.load(\"weights/2dreg/T2.pth\"))\n",
    "\n",
    "rxso2.eval()\n",
    "so2.eval()\n",
    "se2.eval()\n",
    "t2.eval()\n",
    "\n",
    "rxso2_result = []\n",
    "so2_result = []\n",
    "se2_result = []\n",
    "t2_result = []\n",
    "\n",
    "for i in range(1):\n",
    "    imgs = iter(dl).next()[0]\n",
    "    with torch.no_grad():\n",
    "        a = t2(imgs)\n",
    "        t2_result.append(MultivariateNormal(a[0], scale_tril=a[1]).log_prob(imgs.reshape(batch_size, -1)))\n",
    "        \n",
    "        a = so2(imgs)\n",
    "        so2_result.append(MultivariateNormal(a[0], scale_tril=a[1]).log_prob(imgs.reshape(batch_size, -1)))\n",
    "        \n",
    "        a = se2(imgs)\n",
    "        se2_result.append(MultivariateNormal(a[0], scale_tril=a[1]).log_prob(imgs.reshape(batch_size, -1)))\n",
    "        \n",
    "        a = rxso2(imgs)\n",
    "        rxso2_result.append(MultivariateNormal(a[0], scale_tril=a[1]).log_prob(imgs.reshape(batch_size, -1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show(make_grid(iter(dl).next()[0], nrow=5, pad_value=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions import MultivariateNormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.5564])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MultivariateNormal(a[0], scale_tril=a[1]).log_prob(imgs.reshape(batch_size, -1)) / 4096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "liecnp",
   "language": "python",
   "name": "liecnp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
